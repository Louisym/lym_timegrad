{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def plot(target, forecast, prediction_length, prediction_intervals=(50.0, 90.0), color='g', fname=None):\n",
    "label_prefix = \"\"\n",
    "rows = 4\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(24, 24))\n",
    "axx = axs.ravel()\n",
    "seq_len, target_dim = target.shape\n",
    "ps = [50.0] + [\n",
    "50.0 + f * c / 2.0 for c in prediction_intervals for f in [-1.0, +1.0]\n",
    "]\n",
    "percentiles_sorted = sorted(set(ps))\n",
    "def alpha_for_percentile(p):\n",
    "return (p / 100.0) ** 0.3\n",
    "for dim in range(0, min(rows * cols, target_dim)):\n",
    "ax = axx[dim]\n",
    "\n",
    "target[-2 * prediction_length :][dim].plot(ax=ax)\n",
    "ps_data = [forecast.quantile(p / 100.0)[:,dim] for p in percentiles_sorted]\n",
    "i_p50 = len(percentiles_sorted) // 2\n",
    "p50_data = ps_data[i_p50]\n",
    "p50_series = pd.Series(data=p50_data, index=forecast.index)\n",
    "p50_series.plot(color=color, ls=\"-\", label=f\"{label_prefix}median\", ax=ax)\n",
    "for i in range(len(percentiles_sorted) // 2):\n",
    "ptile = percentiles_sorted[i]\n",
    "alpha = alpha_for_percentile(ptile)\n",
    "ax.fill_between(\n",
    "forecast.index,\n",
    "ps_data[i],\n",
    "ps_data[-i - 1],\n",
    "facecolor=color,\n",
    "alpha=alpha,\n",
    "interpolate=True,\n",
    ")\n",
    "# Hack to create labels for the error intervals.\n",
    "# Doesn't actually plot anything, because we only pass a single data point\n",
    "pd.Series(data=p50_data[:1], index=forecast.index[:1]).plot(\n",
    "color=color,\n",
    "alpha=alpha,\n",
    "linewidth=10,\n",
    "label=f\"{label_prefix}{100 - ptile * 2}%\",\n",
    "ax=ax,\n",
    ")\n",
    "\n",
    "legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1] \n",
    "axx[0].legend(legend, loc=\"upper left\")\n",
    "if fname is not None:\n",
    "plt.savefig(fname, bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "return fig\n",
    "\n",
    "# def preprocess_data(dataset):\n",
    "# # 将数据集分为训练集和测试集，前80%作为训练集，后20%作为测试集\n",
    "# train_data = dataset[:int(len(dataset) * 0.8)]\n",
    "# test_data = dataset[int(len(dataset) * 0.8):]\n",
    "# # 将数据集里的单变量数据转为多变量数据\n",
    "# train_grouper = MultivariateGrouper(max_target_dim=min(1000, dataset.col_count))\n",
    "# test_grouper = MultivariateGrouper(num_test_dates=int(len(test_data)), max_target_dim=min(1000, dataset.col_count))\n",
    "# dataset_train = train_grouper(dataset=train_data)\n",
    "# dataset_test = test_grouper(dataset=test_data)\n",
    "# return dataset_train, dataset_test\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "# 将数据集分为训练集和测试集，前80%作为训练集，后20%作为测试集\n",
    "train_data = dataset[:int(len(dataset) * 0.8)]\n",
    "test_data = dataset[int(len(dataset) * 0.8):]\n",
    "# 将数据集里的单变量数据转为多变量数据\n",
    "train_grouper = MultivariateGrouper(max_target_dim=min(1000, dataset.shape[1]))\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(test_data)), max_target_dim=min(1000, dataset.shape[1]))\n",
    "dataset_train = train_grouper(dataset=train_data)\n",
    "dataset_test = test_grouper(dataset=test_data)\n",
    "return dataset_train, dataset_test # 直接返回训练集和测试集\n",
    "\n",
    "def prediction(dataset_train, dataset_test):\n",
    "predictor = estimator.train(dataset_train, num_workers=8)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "predictor=predictor,\n",
    "num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "return forecasts, targets\n",
    "\n",
    "def generate_plot(forecasts, targets, prediction_length):\n",
    "# 调用 plot() 函数生成图像，并捕获返回的 fig 对象\n",
    "fig = plot(\n",
    "target=targets[0],\n",
    "forecast=forecasts[0],\n",
    "prediction_length=prediction_length,\n",
    ")\n",
    "return fig\n",
    "\n",
    "def generate_text(forecasts):\n",
    "df= pd.DataFrame(forecasts)\n",
    "file_path= 'prediction_data.csv'\n",
    "df.to_csv(file_path,index=False)\n",
    "return file_path\n",
    "\n",
    "def rnn_change(choice):\n",
    "estimator.cell_type = choice\n",
    "return None\n",
    "def step_change(step):\n",
    "estimator.diff_steps= step\n",
    "return None\n",
    "def lr_change(lr):\n",
    "estimator.trainer.learning_rate = lr\n",
    "return None\n",
    "\n",
    "def epoch_change(epoch):\n",
    "estimator.trainer.epochs = epoch\n",
    "return None\n",
    "\n",
    "def batchsize_change(batchsize):\n",
    "estimator.trainer.batch_size = batchsize\n",
    "return None\n",
    "\n",
    "def prediction_length_change(prediction_length):\n",
    "estimator.prediction_length = int(prediction_length)\n",
    "return None\n",
    "\n",
    "def beta_end_change(beta_end):\n",
    "estimator.beta_end = beta_end\n",
    "return None\n",
    "\n",
    "def context_length_change(context_length):\n",
    "estimator.context_length = int(context_length)\n",
    "return None\n",
    "\n",
    "def freq_change(freq):\n",
    "estimator.freq = freq\n",
    "return None\n",
    "\n",
    "def change_target_dim(dataset):\n",
    "estimator.target_dim= dataset.col_count\n",
    "return None\n",
    "\n",
    "def load_user_data(file_obj):\n",
    "# 获取上传的文件的路径\n",
    "file_path = file_obj.name\n",
    "# 读取文件并返回 DataFrame\n",
    "ext = os.path.splitext(file_path)[1].lower()\n",
    "if ext == '.csv':\n",
    "df = pd.read_csv(file_path)\n",
    "elif ext == '.xls' or ext == '.xlsx':\n",
    "df = pd.read_excel(file_path)\n",
    "elif ext == '.json':\n",
    "df = pd.read_json(file_path)\n",
    "else:\n",
    "raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "# 返回读取的 DataFrame\n",
    "return df\n",
    "\n",
    "estimator = TimeGradEstimator(\n",
    "target_dim=10, \n",
    "prediction_length=10, \n",
    "context_length=20, \n",
    "cell_type='GRU', \n",
    "input_size=1484, \n",
    "freq='d', \n",
    "loss_type='l2', \n",
    "scaling=True, \n",
    "diff_steps=100, \n",
    "beta_end=0.1, \n",
    "beta_schedule=\"linear\", \n",
    "trainer=Trainer(\n",
    "device=device,\n",
    "epochs=1, \n",
    "learning_rate=1e-3, \n",
    "num_batches_per_epoch=100, \n",
    "batch_size=64, \n",
    ")\n",
    ")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "with gr.Tab(label= 'Timegrad'):\n",
    "with gr.Row():\n",
    "input= gr.File(label= 'Upload file')\n",
    "dataset = gr.State()\n",
    "input.upload(fn=load_user_data, inputs=input, outputs=dataset)\n",
    "with gr.Column():\n",
    "button1= gr.Button(value= 'Electricity')\n",
    "button2= gr.Button(value= 'Stocks')\n",
    "button3= gr.Button(value= '3')\n",
    "with gr.Column():\n",
    "generate_button= gr.Button(value= 'Generate')\n",
    "with gr.Row():\n",
    "dropdown= gr.Dropdown(choices=['Image only', 'Image and Text'], label= 'Format')\n",
    "\n",
    "with gr.Row():\n",
    "with gr.Column():\n",
    "#a title\n",
    "gr.Markdown('diffusion model parameters')\n",
    "with gr.Row():\n",
    "dropdown_rnn= gr.Dropdown(choices=['LSTM', 'GRU'], label= 'RNN')\n",
    "dropdown_rnn.change(fn=rnn_change, inputs=dropdown_rnn, outputs=None)\n",
    "slider_step= gr.Slider(minimum= 1, maximum= 1000, step= 10, label= 'Steps')\n",
    "slider_step.change(fn=step_change, inputs=slider_step, outputs=None)\n",
    "gr.Markdown('train parameters')\n",
    "with gr.Row():\n",
    "slider_lr= gr.Slider(minimum= 0.00001, maximum= 0.01, step= 0.00001, label= 'Learning rate')\n",
    "slider_lr.change(fn=lr_change, inputs=slider_lr, outputs=None)\n",
    "slider_epoch= gr.Slider(minimum= 1, maximum= 20, step= 1, label= 'training epoch')\n",
    "slider_epoch.change(fn=epoch_change, inputs=slider_epoch, outputs=None)\n",
    "with gr.Row():\n",
    "slider_batchsize= gr.Slider(minimum= 0, maximum= 10, step= 1, label= 'batch_size' )\n",
    "slider_batchsize.change(fn=batchsize_change, inputs=slider_batchsize, outputs=None)\n",
    "slider_beta_end= gr.Slider(minimum= 0.00001, maximum= 0.01, step= 0.00001, label= 'beta_end')\n",
    "slider_beta_end.change(fn=beta_end_change, inputs=slider_beta_end, outputs=None)\n",
    "with gr.Row():\n",
    "text_prediction_length= gr.Textbox(label= 'prediction length')\n",
    "text_prediction_length.change(fn=prediction_length_change, inputs=text_prediction_length, outputs=None)\n",
    "text_context_length= gr.Textbox(label= 'context length')\n",
    "text_context_length.change(fn=context_length_change, inputs=text_context_length, outputs=None)\n",
    "dropdown_freq = gr.Dropdown(choices=['D', 'H', 'M', 'S'], label='Frequency')\n",
    "dropdown_freq.change(fn=freq_change, inputs=dropdown_freq, outputs=None)\n",
    "\n",
    "with gr.Row():\n",
    "with gr.Column():\n",
    "prediction_img= gr.Plot()\n",
    "generate_button.click(fn=change_target_dim, inputs=dataset, outputs=None)\n",
    "generate_button.click(fn=preprocess_data, inputs=dataset, outputs=[gr.State(), gr.State()]) # 接收并返回输出\n",
    "generate_button.click(fn=prediction, inputs=[gr.State(), gr.State()], outputs=[gr.State(), gr.State()])\n",
    "generate_button.click(fn=generate_plot, inputs=[gr.State(), gr.State(), int(text_prediction_length)], outputs=prediction_img)\n",
    "prediction_text= gr.File(label= 'prediction data')\n",
    "generate_button.click(fn=generate_text, inputs=None, outputs= prediction_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo.launch(share=True, server_port=6006) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#gradio ui establishment\n",
    "import gradio as gr\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def plot(target, forecast, prediction_length, prediction_intervals=(50.0, 90.0), color='g', fname=None):\n",
    "label_prefix = \"\"\n",
    "rows = 4\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(24, 24))\n",
    "axx = axs.ravel()\n",
    "seq_len, target_dim = target.shape\n",
    "ps = [50.0] + [\n",
    "50.0 + f * c / 2.0 for c in prediction_intervals for f in [-1.0, +1.0]\n",
    "]\n",
    "percentiles_sorted = sorted(set(ps))\n",
    "def alpha_for_percentile(p):\n",
    "return (p / 100.0) ** 0.3\n",
    "for dim in range(0, min(rows * cols, target_dim)):\n",
    "ax = axx[dim]\n",
    "\n",
    "target[-2 * prediction_length :][dim].plot(ax=ax)\n",
    "ps_data = [forecast.quantile(p / 100.0)[:,dim] for p in percentiles_sorted]\n",
    "i_p50 = len(percentiles_sorted) // 2\n",
    "p50_data = ps_data[i_p50]\n",
    "p50_series = pd.Series(data=p50_data, index=forecast.index)\n",
    "p50_series.plot(color=color, ls=\"-\", label=f\"{label_prefix}median\", ax=ax)\n",
    "for i in range(len(percentiles_sorted) // 2):\n",
    "ptile = percentiles_sorted[i]\n",
    "alpha = alpha_for_percentile(ptile)\n",
    "ax.fill_between(\n",
    "forecast.index,\n",
    "ps_data[i],\n",
    "ps_data[-i - 1],\n",
    "facecolor=color,\n",
    "alpha=alpha,\n",
    "interpolate=True,\n",
    ")\n",
    "# Hack to create labels for the error intervals.\n",
    "# Doesn't actually plot anything, because we only pass a single data point\n",
    "pd.Series(data=p50_data[:1], index=forecast.index[:1]).plot(\n",
    "color=color,\n",
    "alpha=alpha,\n",
    "linewidth=10,\n",
    "label=f\"{label_prefix}{100 - ptile * 2}%\",\n",
    "ax=ax,\n",
    ")\n",
    "\n",
    "legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1] \n",
    "axx[0].legend(legend, loc=\"upper left\")\n",
    "if fname is not None:\n",
    "plt.savefig(fname, bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "return fig\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "# 将数据集分为训练集和测试集，前80%作为训练集，后20%作为测试集\n",
    "# train_data = dataset[:int(len(dataset) * 0.8)]\n",
    "# test_data = dataset[int(len(dataset) * 0.8):]\n",
    "# 将数据集里的单变量数据转为多变量数据\n",
    "# train_grouper = MultivariateGrouper(max_target_dim=min(1000, dataset.shape[1]))\n",
    "# test_grouper = MultivariateGrouper(num_test_dates=int(len(test_data)), max_target_dim=min(1000, dataset.shape[1]))\n",
    "train_grouper = MultivariateGrouper(max_target_dim=min(2000, int(dataset.metadata.feat_static_cat[0].cardinality)))\n",
    "\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "max_target_dim=min(2000, int(dataset.metadata.feat_static_cat[0].cardinality)))\n",
    "\n",
    "# dataset_train = train_grouper(dataset=train_data)\n",
    "# dataset_test = test_grouper(dataset=test_data)\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)\n",
    "return dataset_train, dataset_test\n",
    "def prediction(dataset_train, dataset_test):\n",
    "predictor = estimator.train(dataset_train, num_workers=8)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "predictor=predictor,\n",
    "num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "return forecasts, targets\n",
    "\n",
    "\n",
    "\n",
    "def generate_plot(forecasts, targets, prediction_length):\n",
    "# 调用 plot() 函数生成图像，并捕获返回的 fig 对象\n",
    "fig = plot(\n",
    "target=targets[0],\n",
    "forecast=forecasts[0],\n",
    "prediction_length=prediction_length,\n",
    ")\n",
    "return fig\n",
    "\n",
    "def generate_text(forecasts):\n",
    "df= pd.DataFrame(forecasts)\n",
    "file_path= 'prediction_data.csv'\n",
    "df.to_csv(file_path,index=False)\n",
    "return file_path\n",
    "\n",
    "def rnn_change(choice):\n",
    "estimator.cell_type = choice\n",
    "return None\n",
    "def step_change(step):\n",
    "estimator.diff_steps= step\n",
    "return None\n",
    "def lr_change(lr):\n",
    "estimator.trainer.learning_rate = lr\n",
    "return None\n",
    "\n",
    "def epoch_change(epoch):\n",
    "estimator.trainer.epochs = epoch\n",
    "return None\n",
    "\n",
    "def batchsize_change(batchsize):\n",
    "estimator.trainer.batch_size = batchsize\n",
    "return None\n",
    "\n",
    "def prediction_length_change(prediction_length):\n",
    "estimator.prediction_length = int(prediction_length)\n",
    "return None\n",
    "\n",
    "def beta_end_change(beta_end):\n",
    "estimator.beta_end = beta_end\n",
    "return None\n",
    "\n",
    "def context_length_change(context_length):\n",
    "estimator.context_length = int(context_length)\n",
    "return None\n",
    "\n",
    "def freq_change(freq):\n",
    "estimator.freq = freq\n",
    "return None\n",
    "\n",
    "def change_target_dim(dataset):\n",
    "estimator.target_dim= dataset.col_count\n",
    "return None\n",
    "\n",
    "def load_user_data(file_obj):\n",
    "# 获取上传的文件的路径\n",
    "file_path = file_obj.name\n",
    "# 读取文件并返回 DataFrame\n",
    "ext = os.path.splitext(file_path)[1].lower()\n",
    "if ext == '.csv':\n",
    "df = pd.read_csv(file_path)\n",
    "elif ext == '.xls' or ext == '.xlsx':\n",
    "df = pd.read_excel(file_path)\n",
    "elif ext == '.json':\n",
    "df = pd.read_json(file_path)\n",
    "else:\n",
    "raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "# 返回读取的 DataFrame\n",
    "return df\n",
    "\n",
    "# estimator = TimeGradEstimator(\n",
    "# target_dim=10, \n",
    "# prediction_length=10, \n",
    "# context_length=20, \n",
    "# cell_type='GRU', \n",
    "# input_size=1484, \n",
    "# freq='d', \n",
    "# loss_type='l2', \n",
    "# scaling=True, \n",
    "# diff_steps=100, \n",
    "# beta_end=0.1, \n",
    "# beta_schedule=\"linear\", \n",
    "# trainer=Trainer(\n",
    "# device=device,\n",
    "# epochs=1, \n",
    "# learning_rate=1e-3, \n",
    "# num_batches_per_epoch=100, \n",
    "# batch_size=64, \n",
    "# )\n",
    "# )\n",
    "dataset = get_dataset(\"electricity_nips\", regenerate=False)\n",
    "estimator = TimeGradEstimator(\n",
    "target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "prediction_length=dataset.metadata.prediction_length,\n",
    "context_length=dataset.metadata.prediction_length,\n",
    "cell_type='GRU',\n",
    "input_size=1484,\n",
    "freq=dataset.metadata.freq,\n",
    "loss_type='l2',\n",
    "scaling=True,\n",
    "diff_steps=100,\n",
    "beta_end=0.1,\n",
    "beta_schedule=\"linear\",\n",
    "trainer=Trainer(device=device,\n",
    "epochs=20,\n",
    "learning_rate=1e-3,\n",
    "num_batches_per_epoch=100,\n",
    "batch_size=64,)\n",
    ")\n",
    "\n",
    "def full_pipeline(file_obj, prediction_length):\n",
    "# 完整的数据处理流程\n",
    "# dataset = load_user_data(file_obj)\n",
    "dataset = get_dataset(\"electricity_nips\", regenerate=False)\n",
    "dataset_train, dataset_test = preprocess_data(dataset)\n",
    "forecasts, targets = prediction(dataset_train, dataset_test)\n",
    "fig = generate_plot(forecasts, targets, prediction_length)\n",
    "return fig\n",
    "\n",
    "def full_pipeline_text(file_obj, prediction_length):\n",
    "# 完整的数据处理流程\n",
    "dataset = load_user_data(file_obj)\n",
    "dataset_train, dataset_test = preprocess_data(dataset)\n",
    "forecasts, targets = prediction(dataset_train, dataset_test)\n",
    "text_book = generate_text(forecasts)\n",
    "return text_book\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "with gr.Tab(label= 'Timegrad'):\n",
    "with gr.Row():\n",
    "input= gr.File(label= 'Upload file')\n",
    "with gr.Column():\n",
    "button1= gr.Button(value= 'Electricity')\n",
    "button2= gr.Button(value= 'Stocks')\n",
    "button3= gr.Button(value= '3')\n",
    "with gr.Column():\n",
    "generate_button= gr.Button(value= 'Generate')\n",
    "with gr.Row():\n",
    "dropdown= gr.Dropdown(choices=['Image only', 'Image and Text'], label= 'Format')\n",
    "\n",
    "with gr.Row():\n",
    "with gr.Column():\n",
    "#a title\n",
    "gr.Markdown('diffusion model parameters')\n",
    "with gr.Row():\n",
    "dropdown_rnn= gr.Dropdown(choices=['LSTM', 'GRU'], label= 'RNN')\n",
    "dropdown_rnn.change(fn=rnn_change, inputs=dropdown_rnn, outputs=None)\n",
    "slider_step= gr.Slider(minimum= 1, maximum= 1000, step= 10, label= 'Steps')\n",
    "slider_step.change(fn=step_change, inputs=slider_step, outputs=None)\n",
    "gr.Markdown('train parameters')\n",
    "with gr.Row():\n",
    "slider_lr= gr.Slider(minimum= 0.00001, maximum= 0.01, step= 0.00001, label= 'Learning rate')\n",
    "slider_lr.change(fn=lr_change, inputs=slider_lr, outputs=None)\n",
    "slider_epoch= gr.Slider(minimum= 1, maximum= 20, step= 1, label= 'training epoch')\n",
    "slider_epoch.change(fn=epoch_change, inputs=slider_epoch, outputs=None)\n",
    "with gr.Row():\n",
    "slider_batchsize= gr.Slider(minimum= 0, maximum= 10, step= 1, label= 'batch_size' )\n",
    "slider_batchsize.change(fn=batchsize_change, inputs=slider_batchsize, outputs=None)\n",
    "slider_beta_end= gr.Slider(minimum= 0.00001, maximum= 0.01, step= 0.00001, label= 'beta_end')\n",
    "slider_beta_end.change(fn=beta_end_change, inputs=slider_beta_end, outputs=None)\n",
    "with gr.Row():\n",
    "text_prediction_length= gr.Slider(minimum= 1, maximum= 1000, step= 10, label= 'prediction length')\n",
    "text_prediction_length.change(fn=prediction_length_change, inputs=text_prediction_length, outputs=None)\n",
    "text_context_length= gr.Slider(minimum= 1, maximum= 1000, step= 10, label= 'context length')\n",
    "text_context_length.change(fn=context_length_change, inputs=text_context_length, outputs=None)\n",
    "dropdown_freq = gr.Dropdown(choices=['D', 'H', 'M', 'S'], label='Frequency')\n",
    "dropdown_freq.change(fn=freq_change, inputs=dropdown_freq, outputs=None)\n",
    "\n",
    "with gr.Row():\n",
    "with gr.Column():\n",
    "prediction_img= gr.Plot()\n",
    "generate_button.click(fn=full_pipeline, inputs=[input, text_prediction_length], outputs=prediction_img)\n",
    "prediction_text= gr.File(label= 'prediction data')\n",
    "generate_button.click(fn=full_pipeline_text, inputs=[input, text_prediction_length], outputs= prediction_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo.launch(share=True, server_port=6006) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timegrad2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
